# Triton Server Configuration

# Logging level and output
logger {
  level: INFO
  file: "/workspace/triton_model_dir/triton.log"
}

# Metrics server
metrics {
  # Report model metrics to prometheus
  prometheus {
  }
}

# Inference server instance name.
name: "triton-inference-server"

# List of GPUs to use for inference.
gpus: [0]

# Model repository path
model_repository: "/workspace/triton_model_dir"

# HTTP/REST API. If disabled, request must be sent via gRPC only.
http {
  # HTTP port to listen on.
  port: 8000

  # Enable the metrics server for this instance of the inference server.
  enable_metrics: true

  # Path to TLS certificates and keys used by the HTTPS server. The names of the
  # files in the directory should be "<cert>.crt" and "<cert>.key" where <cert> is
  # any name. The first certificate and key found will be used for HTTPS. If no
  # certificate and key are found, HTTPS is disabled. If "allow_http" is also set,
  # a redirect to HTTPS will be returned if an HTTP request is received. If a TLS
  # certificate and key are provided but "allow_http" is not set, then an HTTP
  # error will be returned if an HTTP request is received. Currently only PEM-based
  # certificates and keys are supported; DER-format certificates or keys will not be loaded.

  tls_certificate {
    base_path: "/workspace/triton_model_dir"

    allow_http: true

    redact_headers { }

    server_header: ""

    max_connections: 100000

    max_pending_requests: 5000

    keepalive { idle: 30 seconds }

    backlog: 1024

    readonly { }

    request_timeout { seconds: 30 }

    client_timeout { seconds: 5 }

    model_repository {}

    healthz {}

    healthz2 {}

    metrics {}
}
